{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "!mkdir Data\n",
    "!mkdir Models\n",
    "!mkdir Media\n",
    "!mkdir Media/SSL\n",
    "!mkdir Models/SSL"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "150f472de24bb937"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision.datasets\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import itertools"
   ],
   "id": "b74e605aa6ba45b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CNN Class",
   "id": "cec12fab87b5e8de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Network class definition\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes, size):\n",
    "\n",
    "        # list of the convolutional layers parameters\n",
    "        convLayerNumber = 7\n",
    "        kernels = [9, 7, 7, 5, 5, 3, 3]\n",
    "        paddings = [1, 1, 1, 1, 1, 1, 1]\n",
    "        poolingsStride = [2, 0, 2, 0, 2, 0, 2]\n",
    "        poolingsKernels = [2, 0, 2, 0, 2, 0, 2]\n",
    "        filters = [8, 16, 16, 32, 64, 64, 128]\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # conv layer\n",
    "        self.conv1 = nn.Conv2d(3, filters[0], kernel_size=kernels[0], padding=paddings[0])\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=poolingsKernels[0], stride=poolingsStride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv2d(filters[0], filters[1], kernel_size=kernels[1], padding=paddings[1])\n",
    "        self.conv3 = nn.Conv2d(filters[1], filters[2], kernel_size=kernels[2], padding=paddings[2])\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=poolingsKernels[2], stride=poolingsStride[2])\n",
    "\n",
    "        self.conv4 = nn.Conv2d(filters[2], filters[3], kernel_size=kernels[3], padding=paddings[3])\n",
    "        self.conv5 = nn.Conv2d(filters[3], filters[4], kernel_size=kernels[4], padding=paddings[4])\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=poolingsKernels[4], stride=poolingsStride[4])\n",
    "\n",
    "        self.conv6 = nn.Conv2d(filters[4], filters[5], kernel_size=kernels[5], padding=paddings[5])\n",
    "        self.conv7 = nn.Conv2d(filters[5], filters[6], kernel_size=kernels[6], padding=paddings[6])\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=poolingsKernels[6], stride=poolingsStride[6])\n",
    "\n",
    "        # custom code to calculate the size of the first layer\n",
    "        for i in range(convLayerNumber):\n",
    "            size = (size - kernels[i] + 2 * paddings[i]) / 1 + 1\n",
    "            if poolingsKernels[i] != 0:\n",
    "                size = int((size - poolingsKernels[i]) / poolingsStride[i] + 1)\n",
    "\n",
    "        fc1_input_size = filters[6] * size * size\n",
    "\n",
    "        print(\"First layer size: \", fc1_input_size)\n",
    "\n",
    "        # dense nn layers\n",
    "        self.fc1 = nn.Linear(fc1_input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Feature extraction\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = F.leaky_relu(self.conv3(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv4(x))\n",
    "        x = F.leaky_relu(self.conv5(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv6(x))\n",
    "        x = F.leaky_relu(self.conv7(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # Flatten the tensor for the fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Classification\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "id": "ba3b450727368461",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n",
    "print(\"running on: \", device)\n",
    "\n",
    "# MacOS specific code\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print(x)\n",
    "else:\n",
    "    print(\"MPS device not found.\")\n",
    "\n",
    "# Image size\n",
    "size = 128\n",
    "\n",
    "# mean and std values for the dataset calculated\n",
    "mean = [0.6388, 0.5446, 0.4452]\n",
    "std = [0.2252, 0.2437, 0.2661]\n",
    "\n",
    "# network\n",
    "net = Net(num_classes=251, size=size)\n",
    "\n",
    "# torch-summary to check the network parameters\n",
    "summary(net, (3, size, size))"
   ],
   "id": "e85fff0cb71c53c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load net to device\n",
    "net.to(device)\n",
    "\n",
    "# for kaggle use: \"/kaggle/input/supervised/\"\n",
    "datasetPath = './Data/'\n",
    "# datasetPath = '/kaggle/input/supervised/'\n",
    "simpleCNNLossOvertime = []\n",
    "simpleCNNAccuracyOvertime = []\n",
    "\n",
    "# data transformations pipeline\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((size, size), antialias = True),\n",
    "    torchvision.transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# load the dataset\n",
    "trainSet = torchvision.datasets.ImageFolder(root= datasetPath + 'processedData/processed_train_set', transform=transforms)\n",
    "testSet = torchvision.datasets.ImageFolder(root= datasetPath + 'processedData/processed_test_set', transform=transforms)\n",
    "valSet = torchvision.datasets.ImageFolder(root= datasetPath + 'processedData/processed_val_set', transform=transforms)\n",
    "\n",
    "# data loaders\n",
    "trainLoader = DataLoader(trainSet, batch_size=64, shuffle=True, num_workers=4)\n",
    "testLoader = DataLoader(testSet, batch_size=64, shuffle=True, num_workers=4)\n",
    "valLoader = DataLoader(valSet, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "# print the dataset sizes\n",
    "print(\"Training:\", len(trainLoader.dataset))\n",
    "print(\"Validation:\", len(valLoader.dataset))\n",
    "print(\"Test:\", len(testLoader.dataset))"
   ],
   "id": "36d7e8b2032180f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# criterion for classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# number of epochs\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # tqdm to show a progress bar \n",
    "    for i, data in tqdm(enumerate(trainLoader, 0), total=len(trainLoader)):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    simpleCNNLossOvertime.append(round(running_loss/len(trainLoader), 2))\n",
    "    \n",
    "    # put the network in evaluation mode\n",
    "    net.eval()\n",
    "\n",
    "    # check accuracy on val set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(valLoader, total=len(valLoader)):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    accuracy = round(accuracy, 2)\n",
    "    simpleCNNAccuracyOvertime.append(accuracy)\n",
    "    print(f\"Epoch {epoch + 1}, loss: {round(running_loss/len(trainLoader), 2)}, accuracy: {accuracy}\")\n",
    "\n",
    "    # save model after each epoch\n",
    "    torch.save(net.state_dict(), f\"Models/{size}-model_{epoch}.pth\")\n",
    "    \n",
    "    # put the network back in training mode\n",
    "    net.train()\n",
    "\n",
    "print('Finished Training')\n",
    "print(simpleCNNLossOvertime)\n",
    "print(simpleCNNAccuracyOvertime)\n",
    "\n",
    "# plot loss and accuracy in separate graphs\n",
    "plt.plot(simpleCNNLossOvertime)\n",
    "plt.title('Simple CNN loss')\n",
    "plt.grid()\n",
    "plt.savefig('Media/loss.png')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(simpleCNNAccuracyOvertime)\n",
    "plt.title('Simple CNN accuracy')\n",
    "plt.grid()\n",
    "plt.savefig('Media/accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Starting testing\")\n",
    "\n",
    "# put the network in evaluation mode\n",
    "net.eval()\n",
    "\n",
    "# validate the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(testLoader, total=len(testLoader)):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_true += labels.tolist()\n",
    "        y_pred += predicted.tolist()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Testings accuracy: {accuracy}\")\n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(f\"F1 score: {f1}\")"
   ],
   "id": "165af3a955f18454",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Self Supervised Learning Task",
   "id": "a4125b0c4c752760"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataset class which extends the Dataset class\n",
    "class JigsawPuzzleDataset(Dataset):\n",
    "    def __init__(self, dataset, grid_size=2):\n",
    "        self.dataset = dataset\n",
    "        self.grid_size = grid_size\n",
    "        self.permutations = self._generate_permutations(grid_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, _ = self.dataset[index]\n",
    "        image_pieces, correct_order = self._divide_image(image)\n",
    "        shuffled_pieces, shuffled_order = self._shuffle_pieces(image_pieces, correct_order)\n",
    "\n",
    "        # Create a new blank image of the correct size\n",
    "        reconstructed_image = torch.zeros_like(image)\n",
    "\n",
    "        piece_w, piece_h = image.shape[1] // self.grid_size, image.shape[2] // self.grid_size\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                # Calculate the position of the piece in the reconstructed image\n",
    "                pos = (j * piece_w, i * piece_h)\n",
    "                # Paste the piece at the correct position\n",
    "                reconstructed_image[:, pos[1]:pos[1]+piece_h, pos[0]:pos[0]+piece_w] = shuffled_pieces[i * self.grid_size + j]\n",
    "\n",
    "        # One-hot encode the permutation index\n",
    "        permutation_index = self.permutations.index(tuple(shuffled_order))\n",
    "        label = torch.zeros(len(self.permutations), dtype=torch.float)\n",
    "        label[permutation_index] = 1.0\n",
    "\n",
    "        return reconstructed_image, label\n",
    "\n",
    "    def _divide_image(self, image):\n",
    "        pieces = []\n",
    "\n",
    "        piece_w, piece_h = image.shape[1] // self.grid_size, image.shape[2] // self.grid_size\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                piece = image[:, i*piece_h:(i+1)*piece_h, j*piece_w:(j+1)*piece_w]\n",
    "                pieces.append(piece)\n",
    "\n",
    "        correct_order = list(range(self.grid_size ** 2))\n",
    "        return pieces, correct_order\n",
    "\n",
    "    def _shuffle_pieces(self, pieces):\n",
    "        shuffled_order = random.choice(self.permutations)\n",
    "        shuffled_pieces = [pieces[i] for i in shuffled_order]\n",
    "        return shuffled_pieces, shuffled_order\n",
    "\n",
    "    def _generate_permutations(self, grid_size):\n",
    "        indices = list(range(grid_size ** 2))\n",
    "        permutations = list(itertools.permutations(indices))\n",
    "        return permutations"
   ],
   "id": "eef554da3dd8cd39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# define new network class, that extends the previous one\n",
    "class NetWithJigSawPrediction(Net):\n",
    "    def __init__(self, num_classes, size):\n",
    "        super(NetWithJigSawPrediction, self).__init__(num_classes, size)\n",
    "        \n",
    "        # 24 corresponds to the number of permutations of the image pieces\n",
    "        self.rotation_fc = nn.Linear(self.fc1.in_features, 24)\n",
    "\n",
    "    def forward(self, x, predictJigSaw=False):\n",
    "        # Feature extraction\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = F.leaky_relu(self.conv3(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv4(x))\n",
    "        x = F.leaky_relu(self.conv5(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv6(x))\n",
    "        x = F.leaky_relu(self.conv7(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # Flatten the tensor for the fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        if predictJigSaw:\n",
    "            return self.rotation_fc(x)\n",
    "        else:\n",
    "            x = F.leaky_relu(self.fc1(x))\n",
    "            x = self.dropout(x)\n",
    "            return self.fc2(x)"
   ],
   "id": "a37c1a535e5ccfe6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# as before use the same mean and std values\n",
    "mean = [0.6388, 0.5446, 0.4452]\n",
    "std = [0.2252, 0.2437, 0.2661]\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((128, 128), antialias= True),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# load the dataset\n",
    "trainSet = torchvision.datasets.ImageFolder(root= datasetPath + 'processedData/processed_train_set', transform=transforms)\n",
    "testSet = torchvision.datasets.ImageFolder(root= datasetPath + 'processedData/processed_test_set', transform=transforms)\n",
    "valSet = torchvision.datasets.ImageFolder(root= datasetPath + 'processedData/processed_val_set', transform=transforms)\n",
    "\n",
    "jigsaw_dataset = JigsawPuzzleDataset(trainSet)\n",
    "jigsaw_datasetTest = JigsawPuzzleDataset(testSet)\n",
    "jigsaw_datasetVal = JigsawPuzzleDataset(valSet)\n",
    "\n",
    "batch_size = 64\n",
    "jigsaw_loader = DataLoader(jigsaw_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "jigsaw_loaderTest = DataLoader(jigsaw_datasetTest, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "jigsaw_loaderVal = DataLoader(jigsaw_datasetVal, batch_size=batch_size, shuffle=True, num_workers=4)"
   ],
   "id": "7937000aa758ce63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize the SSL model\n",
    "ssl_model = NetWithJigSawPrediction(num_classes=251, size=128)\n",
    "ssl_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(ssl_model.parameters(), lr=0.001)\n",
    "\n",
    "# learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "SSLLossOvertime = []\n",
    "SSLAccuracyOvertime = []\n",
    "\n",
    "ssl_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(jigsaw_loader, total=len(jigsaw_loader)):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ssl_model(images, predictJigSaw=True)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    SSLLossOvertime.append(round(running_loss / len(jigsaw_loader), 2))\n",
    "\n",
    "    # put the model in evaluation mode\n",
    "    ssl_model.eval()\n",
    "\n",
    "    # check accuracy on val set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(jigsaw_loaderVal, total=len(jigsaw_loaderVal)):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = ssl_model(images, predictJigSaw=True)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    accuracy = round(accuracy, 2)\n",
    "    SSLAccuracyOvertime.append(accuracy)\n",
    "    print(f\"Epoch {epoch + 1}, loss: {round(running_loss / len(jigsaw_loader), 2)}, accuracy: {accuracy}\")\n",
    "\n",
    "    # put the model back in training mode\n",
    "    ssl_model.train()\n",
    "\n",
    "    # save the model after each epoch\n",
    "    torch.save(ssl_model.state_dict(), f\"ssl_model_epoch_{epoch + 1}.pth\")\n",
    "\n",
    "print(\"Finished SSL Training\")\n",
    "print(SSLLossOvertime)\n",
    "print(SSLAccuracyOvertime)\n",
    "\n",
    "# plot loss and accuracy in separate graphs\n",
    "plt.plot(SSLLossOvertime)\n",
    "plt.title('SSL Loss')\n",
    "plt.grid()\n",
    "plt.savefig('Media/SSLLoss.png')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(SSLAccuracyOvertime)\n",
    "plt.title('SSL Accuracy')\n",
    "plt.grid()\n",
    "plt.savefig('Media/SSLAccuracy.png')\n",
    "plt.close()\n",
    "\n",
    "# start testing\n",
    "print(\"Starting testing\")\n",
    "\n",
    "# put the model in evaluation mode\n",
    "ssl_model.eval()\n",
    "\n",
    "# validate the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(jigsaw_loaderTest, total=len(jigsaw_loaderTest)):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = ssl_model(images, predictJigSaw=True)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        labels = torch.argmax(labels, dim=1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Testings accuracy: {accuracy}\")\n",
    "\n",
    "print(\"train the CNN with the new weights\")\n",
    "\n",
    "classification_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((128, 128)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "classification_dataset = torchvision.datasets.ImageFolder(root=datasetPath + \"processedData/processed_train_set\",\n",
    "                                              transform=classification_transform)\n",
    "classification_datasetTest = torchvision.datasets.ImageFolder(root=datasetPath + \"processedData/processed_test_set\",\n",
    "                                                  transform=classification_transform)\n",
    "classification_datasetVal = torchvision.datasets.ImageFolder(root=datasetPath +  \"processedData/processed_val_set\",\n",
    "                                                 transform=classification_transform)\n",
    "\n",
    "classification_loader = DataLoader(classification_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "classification_loaderTest = DataLoader(classification_datasetTest, batch_size=batch_size, shuffle=True,\n",
    "                                       num_workers=4)\n",
    "classification_loaderVal = DataLoader(classification_datasetVal, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Fine-tune the SSL model for classification\n",
    "ssl_model.fc2 = nn.Linear(ssl_model.fc2.in_features, 251)  # Update the final layer for 251 classes\n",
    "ssl_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(ssl_model.parameters(), lr=0.001)\n",
    "\n",
    "# learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "SSLCNNLossOvertime = []\n",
    "SSLCNNAccuracyOvertime = []\n",
    "\n",
    "ssl_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(classification_loader, total=len(classification_loader)):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ssl_model(images, predictJigSaw=False)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    SSLCNNLossOvertime.append(round(running_loss / len(classification_loader), 2))\n",
    "\n",
    "    # put the model in evaluation mode\n",
    "    ssl_model.eval()\n",
    "\n",
    "    # check accuracy on val set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(classification_loaderVal, total=len(classification_loaderVal)):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = ssl_model(images, predictJigSaw=False)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    accuracy = round(accuracy, 2)\n",
    "    SSLCNNAccuracyOvertime.append(accuracy)\n",
    "    print(f\"Epoch {epoch + 1}, loss: {round(running_loss / len(classification_loader), 2)}, accuracy: {accuracy}\")\n",
    "\n",
    "    # put the model back in training mode\n",
    "    ssl_model.train()\n",
    "\n",
    "    # save the model after each epoch\n",
    "    torch.save(ssl_model.state_dict(), f\"ssl_model_classification_epoch_{epoch + 1}.pth\")\n",
    "\n",
    "print(\"Finished Classification Training\")\n",
    "print(SSLCNNLossOvertime)\n",
    "print(SSLCNNAccuracyOvertime)\n",
    "\n",
    "# plot loss and accuracy in separate graphs\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SSLCNNLossOvertime)\n",
    "plt.title('SSL CNN Loss')\n",
    "plt.grid()\n",
    "plt.savefig('Media/classification_loss.png')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(SSLCNNAccuracyOvertime)\n",
    "plt.title('SSL CNN Accuracy')\n",
    "plt.grid()\n",
    "plt.savefig('Media/classification_accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "# start testing\n",
    "print(\"Starting testing\")\n",
    "\n",
    "# put the model in evaluation mode\n",
    "ssl_model.eval()\n",
    "\n",
    "# validate the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(classification_loaderTest, total=len(classification_loaderTest)):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = ssl_model(images, predictJigSaw=False)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        y_true += labels.tolist()\n",
    "        y_pred += predicted.tolist()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Testings accuracy: {accuracy}\")\n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(f\"F1 score: {f1}\")"
   ],
   "id": "a5044ecd86edf89e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting compared loss and accuracies of the models\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SSLCNNLossOvertime)\n",
    "plt.plot(simpleCNNLossOvertime)\n",
    "plt.title('CNN Loss Compared')\n",
    "plt.legend(['SSL CNN', 'CNN'])\n",
    "plt.grid()\n",
    "plt.savefig('./Media/lossCompared.png')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SSLCNNAccuracyOvertime)\n",
    "plt.plot(simpleCNNAccuracyOvertime)\n",
    "plt.title('CNN Accuracy Compared')\n",
    "plt.legend(['SSL CNN', 'CNN'])\n",
    "plt.grid()\n",
    "plt.savefig('./Media/accuracyCompared.png')\n",
    "plt.close()"
   ],
   "id": "6c58f7c19f24b602",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
