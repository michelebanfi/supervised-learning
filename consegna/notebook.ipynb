{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creation of the folder to save the outputs",
   "id": "cdeca14a2b457132"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "!mkdir Data\n",
    "!mkdir Models\n",
    "!mkdir Media\n",
    "!mkdir Media/SSL\n",
    "!mkdir Models/SSL"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameters",
   "id": "d1728356398f3772"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T09:46:56.236729Z",
     "start_time": "2024-06-14T09:46:56.212001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# faster way to implement the dictionary, instead of relying on a .txt file\n",
    "dictionary= {0: 'macaron',\n",
    " 1: 'beignet',\n",
    " 2: 'cruller',\n",
    " 3: 'cockle_food',\n",
    " 4: 'samosa',\n",
    " 5: 'tiramisu',\n",
    " 6: 'tostada',\n",
    " 7: 'moussaka',\n",
    " 8: 'dumpling',\n",
    " 9: 'sashimi',\n",
    " 10: 'knish',\n",
    " 11: 'croquette',\n",
    " 12: 'couscous',\n",
    " 13: 'porridge',\n",
    " 14: 'stuffed_cabbage',\n",
    " 15: 'seaweed_salad',\n",
    " 16: 'chow_mein',\n",
    " 17: 'rigatoni',\n",
    " 18: 'beef_tartare',\n",
    " 19: 'cannoli',\n",
    " 20: 'foie_gras',\n",
    " 21: 'cupcake',\n",
    " 22: 'osso_buco',\n",
    " 23: 'pad_thai',\n",
    " 24: 'poutine',\n",
    " 25: 'ramen',\n",
    " 26: 'pulled_pork_sandwich',\n",
    " 27: 'bibimbap',\n",
    " 28: 'chicken_kiev',\n",
    " 29: 'apple_pie',\n",
    " 30: 'risotto',\n",
    " 31: 'fruitcake',\n",
    " 32: 'chop_suey',\n",
    " 33: 'haggis',\n",
    " 34: 'scrambled_eggs',\n",
    " 35: 'frittata',\n",
    " 36: 'scampi',\n",
    " 37: 'sushi',\n",
    " 38: 'orzo',\n",
    " 39: 'fritter',\n",
    " 40: 'nacho',\n",
    " 41: 'beef_stroganoff',\n",
    " 42: 'beef_wellington',\n",
    " 43: 'spring_roll',\n",
    " 44: 'savarin',\n",
    " 45: 'crayfish_food',\n",
    " 46: 'souffle',\n",
    " 47: 'adobo',\n",
    " 48: 'streusel',\n",
    " 49: 'deviled_egg',\n",
    " 50: 'escargot',\n",
    " 51: 'club_sandwich',\n",
    " 52: 'carrot_cake',\n",
    " 53: 'falafel',\n",
    " 54: 'farfalle',\n",
    " 55: 'terrine',\n",
    " 56: 'poached_egg',\n",
    " 57: 'gnocchi',\n",
    " 58: 'bubble_and_squeak',\n",
    " 59: 'egg_roll',\n",
    " 60: 'caprese_salad',\n",
    " 61: 'sauerkraut',\n",
    " 62: 'creme_brulee',\n",
    " 63: 'pavlova',\n",
    " 64: 'fondue',\n",
    " 65: 'scallop',\n",
    " 66: 'jambalaya',\n",
    " 67: 'tempura',\n",
    " 68: 'chocolate_cake',\n",
    " 69: 'potpie',\n",
    " 70: 'spaghetti_bolognese',\n",
    " 71: 'sukiyaki',\n",
    " 72: 'applesauce',\n",
    " 73: 'baklava',\n",
    " 74: 'salisbury_steak',\n",
    " 75: 'linguine',\n",
    " 76: 'edamame',\n",
    " 77: 'coq_au_vin',\n",
    " 78: 'tamale',\n",
    " 79: 'macaroni_and_cheese',\n",
    " 80: 'kedgeree',\n",
    " 81: 'garlic_bread',\n",
    " 82: 'beet_salad',\n",
    " 83: 'steak_tartare',\n",
    " 84: 'vermicelli',\n",
    " 85: 'pate',\n",
    " 86: 'pancake',\n",
    " 87: 'tetrazzini',\n",
    " 88: 'onion_rings',\n",
    " 89: 'red_velvet_cake',\n",
    " 90: 'compote',\n",
    " 91: 'lobster_food',\n",
    " 92: 'chicken_curry',\n",
    " 93: 'chicken_wing',\n",
    " 94: 'caesar_salad',\n",
    " 95: 'succotash',\n",
    " 96: 'hummus',\n",
    " 97: 'fish_and_chips',\n",
    " 98: 'lasagna',\n",
    " 99: 'lutefisk',\n",
    " 100: 'sloppy_joe',\n",
    " 101: 'gingerbread',\n",
    " 102: 'crab_cake',\n",
    " 103: 'sauerbraten',\n",
    " 104: 'peking_duck',\n",
    " 105: 'guacamole',\n",
    " 106: 'ham_sandwich',\n",
    " 107: 'crumpet',\n",
    " 108: 'taco',\n",
    " 109: 'strawberry_shortcake',\n",
    " 110: 'clam_chowder',\n",
    " 111: 'cottage_pie',\n",
    " 112: 'croque_madame',\n",
    " 113: 'french_onion_soup',\n",
    " 114: 'beef_carpaccio',\n",
    " 115: 'torte',\n",
    " 116: 'poi',\n",
    " 117: 'crab_food',\n",
    " 118: 'bacon_and_eggs',\n",
    " 119: 'coffee_cake',\n",
    " 120: 'custard',\n",
    " 121: 'syllabub',\n",
    " 122: 'pork_chop',\n",
    " 123: 'fried_rice',\n",
    " 124: 'boiled_egg',\n",
    " 125: 'galantine',\n",
    " 126: 'brisket',\n",
    " 127: 'reuben',\n",
    " 128: 'schnitzel',\n",
    " 129: 'ambrosia_food',\n",
    " 130: 'gyoza',\n",
    " 131: 'jerky',\n",
    " 132: 'ravioli',\n",
    " 133: 'fried_calamari',\n",
    " 134: 'spaghetti_carbonara',\n",
    " 135: 'miso_soup',\n",
    " 136: 'frozen_yogurt',\n",
    " 137: 'wonton',\n",
    " 138: 'panna_cotta',\n",
    " 139: 'french_toast',\n",
    " 140: 'enchilada',\n",
    " 141: 'ceviche',\n",
    " 142: 'fettuccine',\n",
    " 143: 'chili',\n",
    " 144: 'flan',\n",
    " 145: 'kabob',\n",
    " 146: 'sponge_cake',\n",
    " 147: 'casserole',\n",
    " 148: 'paella',\n",
    " 149: 'blancmange',\n",
    " 150: 'bruschetta',\n",
    " 151: 'tortellini',\n",
    " 152: 'grilled_salmon',\n",
    " 153: 'french_fries',\n",
    " 154: 'shrimp_and_grits',\n",
    " 155: 'churro',\n",
    " 156: 'donut',\n",
    " 157: 'meat_loaf_food',\n",
    " 158: 'meatball',\n",
    " 159: 'scrapple',\n",
    " 160: 'strudel',\n",
    " 161: 'coconut_cake',\n",
    " 162: 'marble_cake',\n",
    " 163: 'filet_mignon',\n",
    " 164: 'hamburger',\n",
    " 165: 'fried_egg',\n",
    " 166: 'tuna_tartare',\n",
    " 167: 'penne',\n",
    " 168: 'eggs_benedict',\n",
    " 169: 'bread_pudding',\n",
    " 170: 'takoyaki',\n",
    " 171: 'tenderloin',\n",
    " 172: 'chocolate_mousse',\n",
    " 173: 'baked_alaska',\n",
    " 174: 'hot_dog',\n",
    " 175: 'confit',\n",
    " 176: 'ham_and_eggs',\n",
    " 177: 'biryani',\n",
    " 178: 'greek_salad',\n",
    " 179: 'huevos_rancheros',\n",
    " 180: 'tagliatelle',\n",
    " 181: 'stuffed_peppers',\n",
    " 182: 'cannelloni',\n",
    " 183: 'pizza',\n",
    " 184: 'sausage_roll',\n",
    " 185: 'chicken_quesadilla',\n",
    " 186: 'hot_and_sour_soup',\n",
    " 187: 'prime_rib',\n",
    " 188: 'cheesecake',\n",
    " 189: 'limpet_food',\n",
    " 190: 'ziti',\n",
    " 191: 'mussel',\n",
    " 192: 'manicotti',\n",
    " 193: 'ice_cream',\n",
    " 194: 'waffle',\n",
    " 195: 'oyster',\n",
    " 196: 'omelette',\n",
    " 197: 'clam_food',\n",
    " 198: 'burrito',\n",
    " 199: 'roulade',\n",
    " 200: 'lobster_bisque',\n",
    " 201: 'grilled_cheese_sandwich',\n",
    " 202: 'gyro',\n",
    " 203: 'pound_cake',\n",
    " 204: 'pho',\n",
    " 205: 'lobster_roll_sandwich',\n",
    " 206: 'baby_back_rib',\n",
    " 207: 'tapenade',\n",
    " 208: 'pepper_steak',\n",
    " 209: 'welsh_rarebit',\n",
    " 210: 'pilaf',\n",
    " 211: 'dolmas',\n",
    " 212: 'coquilles_saint_jacques',\n",
    " 213: 'veal_cordon_bleu',\n",
    " 214: 'shirred_egg',\n",
    " 215: 'barbecued_wing',\n",
    " 216: 'lobster_thermidor',\n",
    " 217: 'steak_au_poivre',\n",
    " 218: 'huitre',\n",
    " 219: 'chiffon_cake',\n",
    " 220: 'profiterole',\n",
    " 221: 'toad_in_the_hole',\n",
    " 222: 'chicken_marengo',\n",
    " 223: 'victoria_sandwich',\n",
    " 224: 'tamale_pie',\n",
    " 225: 'boston_cream_pie',\n",
    " 226: 'fish_stick',\n",
    " 227: 'crumb_cake',\n",
    " 228: 'chicken_provencale',\n",
    " 229: 'vol_au_vent',\n",
    " 230: 'entrecote',\n",
    " 231: 'carbonnade_flamande',\n",
    " 232: 'bacon_lettuce_tomato_sandwich',\n",
    " 233: 'scotch_egg',\n",
    " 234: 'pirogi',\n",
    " 235: 'peach_melba',\n",
    " 236: 'upside_down_cake',\n",
    " 237: 'applesauce_cake',\n",
    " 238: 'rugulah',\n",
    " 239: 'rock_cake',\n",
    " 240: 'barbecued_spareribs',\n",
    " 241: 'beef_bourguignonne',\n",
    " 242: 'rissole',\n",
    " 243: 'mostaccioli',\n",
    " 244: 'apple_turnover',\n",
    " 245: 'matzo_ball',\n",
    " 246: 'chicken_cordon_bleu',\n",
    " 247: 'eccles_cake',\n",
    " 248: 'moo_goo_gai_pan',\n",
    " 249: 'buffalo_wing',\n",
    " 250: 'stuffed_tomato'}"
   ],
   "id": "d824d4b0b01de77d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T09:46:56.242242Z",
     "start_time": "2024-06-14T09:46:56.238720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 13\n",
    "batch_size = 64\n",
    "\n",
    "# image size\n",
    "size = 128\n",
    "\n",
    "# mean and std values for the dataset calculated\n",
    "mean = [0.6388, 0.5446, 0.4452]\n",
    "std = [0.2252, 0.2437, 0.2661]"
   ],
   "id": "c265a3497e97c61e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "150f472de24bb937"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T12:24:58.439200Z",
     "start_time": "2024-06-14T12:24:51.965925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# imports\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision.datasets\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import itertools\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import numpy as np"
   ],
   "id": "b74e605aa6ba45b1",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CNN Class",
   "id": "cec12fab87b5e8de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T12:24:59.960446Z",
     "start_time": "2024-06-14T12:24:59.946243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# network class definition\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes, size):\n",
    "        \n",
    "        # list of the convolutional layers parameters for the Small network\n",
    "        convLayerNumber = 7\n",
    "        kernels = [9, 7, 7, 5, 5, 3, 3]\n",
    "        paddings = [0, 0, 0, 0, 0, 0, 0]\n",
    "        poolingsStride = [2, 0, 2, 0, 2, 0, 2]\n",
    "        poolingsKernels = [2, 0, 2, 0, 2, 0, 2]\n",
    "        filters = [8, 16, 16, 32, 64, 64, 128]\n",
    "        \n",
    "        # list of the convolutional layers parameters for the Big network        \n",
    "        # convLayerNumber = 7\n",
    "        # kernels = [11, 7, 7, 5, 5, 3, 3]\n",
    "        # paddings = [1, 1, 1, 1, 1, 1, 1]\n",
    "        # poolingsStride = [2, 0, 2, 0, 2, 0, 2]\n",
    "        # poolingsKernels = [2, 0, 2, 0, 2, 0, 2]\n",
    "        # filters = [8, 16, 16, 32, 64, 64, 107]\n",
    "\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, filters[0], kernel_size=kernels[0], padding=paddings[0])\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=poolingsKernels[0], stride=poolingsStride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv2d(filters[0], filters[1], kernel_size=kernels[1], padding=paddings[1])\n",
    "        self.conv3 = nn.Conv2d(filters[1], filters[2], kernel_size=kernels[2], padding=paddings[2])\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=poolingsKernels[2], stride=poolingsStride[2])\n",
    "\n",
    "        self.conv4 = nn.Conv2d(filters[2], filters[3], kernel_size=kernels[3], padding=paddings[3])\n",
    "        self.conv5 = nn.Conv2d(filters[3], filters[4], kernel_size=kernels[4], padding=paddings[4])\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=poolingsKernels[4], stride=poolingsStride[4])\n",
    "\n",
    "        self.conv6 = nn.Conv2d(filters[4], filters[5], kernel_size=kernels[5], padding=paddings[5])\n",
    "        self.conv7 = nn.Conv2d(filters[5], filters[6], kernel_size=kernels[6], padding=paddings[6])\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=poolingsKernels[6], stride=poolingsStride[6])\n",
    "\n",
    "        # custom code to calculate the size of the first layer\n",
    "        for i in range(convLayerNumber):\n",
    "            size = (size - kernels[i] + 2 * paddings[i]) / 1 + 1\n",
    "            if poolingsKernels[i] != 0:\n",
    "                size = int((size - poolingsKernels[i]) / poolingsStride[i] + 1)\n",
    "\n",
    "        fc1_input_size = filters[6] * size * size\n",
    "\n",
    "        print(\"First layer size: \", fc1_input_size)\n",
    "\n",
    "        # dense nn layers\n",
    "        self.fc1 = nn.Linear(fc1_input_size, 251)\n",
    "        self.fc2 = nn.Linear(251, num_classes)\n",
    "        \n",
    "        # 24 corresponds to the number of permutations of the image pieces (SSL task)\n",
    "        self.jigsaw_fc = nn.Linear(self.fc2.in_features, 24)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "        \n",
    "    def forward(self, x, predictJigSaw=False):\n",
    "        \n",
    "        # feature extraction\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = F.leaky_relu(self.conv3(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv4(x))\n",
    "        x = F.leaky_relu(self.conv5(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv6(x))\n",
    "        x = F.leaky_relu(self.conv7(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # classification\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        if predictJigSaw:\n",
    "            return self.jigsaw_fc(x)\n",
    "        else:\n",
    "            return self.fc2(x)"
   ],
   "id": "ba3b450727368461",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T12:25:03.259582Z",
     "start_time": "2024-06-14T12:25:02.753475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n",
    "print(\"running on: \", device)\n",
    "\n",
    "# MacOS specific code\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print(x)\n",
    "else:\n",
    "    print(\"MPS device not found.\")\n",
    "\n",
    "# network\n",
    "net = Net(num_classes=251, size=size)\n",
    "\n",
    "# torch-summary to check the network parameters\n",
    "summary(net, (3, size, size))"
   ],
   "id": "e85fff0cb71c53c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on:  cpu\n",
      "tensor([1.], device='mps:0')\n",
      "First layer size:  2304\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 8, 122, 122]           1,184\n",
      "         MaxPool2d-2            [-1, 8, 61, 61]               0\n",
      "            Conv2d-3           [-1, 16, 57, 57]           3,216\n",
      "            Conv2d-4           [-1, 16, 53, 53]           6,416\n",
      "         MaxPool2d-5           [-1, 16, 26, 26]               0\n",
      "            Conv2d-6           [-1, 32, 24, 24]           4,640\n",
      "            Conv2d-7           [-1, 64, 22, 22]          18,496\n",
      "         MaxPool2d-8           [-1, 64, 11, 11]               0\n",
      "            Conv2d-9             [-1, 64, 9, 9]          36,928\n",
      "           Conv2d-10            [-1, 256, 7, 7]         147,712\n",
      "        MaxPool2d-11            [-1, 256, 3, 3]               0\n",
      "           Linear-12                  [-1, 305]         703,025\n",
      "          Dropout-13                  [-1, 305]               0\n",
      "           Linear-14                  [-1, 251]          76,806\n",
      "================================================================\n",
      "Total params: 998,423\n",
      "Trainable params: 998,423\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 2.55\n",
      "Params size (MB): 3.81\n",
      "Estimated Total Size (MB): 6.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:39:34.394424Z",
     "start_time": "2024-06-13T18:39:32.288570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load net to device\n",
    "net.to(device)\n",
    "\n",
    "# for kaggle use: \"/kaggle/input/supervised/\"\n",
    "# datasetPath = './Data/'\n",
    "datasetPath = '/kaggle/input/supervised/'\n",
    "simpleCNNLossOvertime = []\n",
    "simpleCNNAccuracyOvertime = []\n",
    "\n",
    "# data transformations pipeline\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((size, size), antialias = True),\n",
    "    torchvision.transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# load the dataset\n",
    "trainSet = torchvision.datasets.ImageFolder(root= datasetPath + 'processedData/processed_train_set', transform=transforms)\n",
    "testSet = torchvision.datasets.ImageFolder(root= datasetPath + 'processedData/processed_test_set', transform=transforms)\n",
    "valSet = torchvision.datasets.ImageFolder(root= datasetPath + 'processedData/processed_val_set', transform=transforms)\n",
    "\n",
    "# data loaders\n",
    "trainLoader = DataLoader(trainSet, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "testLoader = DataLoader(testSet, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valLoader = DataLoader(valSet, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# print the dataset sizes\n",
    "print(\"Training:\", len(trainLoader.dataset))\n",
    "print(\"Validation:\", len(valLoader.dataset))\n",
    "print(\"Test:\", len(testLoader.dataset))"
   ],
   "id": "36d7e8b2032180f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 88977\n",
      "Validation: 29600\n",
      "Test: 47976\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# criterion for classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer and scheduler for the Small network\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# learning rate scheduler\n",
    "scheduler = CosineAnnealingLR(optimizer, num_epochs, 0, -1)\n",
    "\n",
    "# optimizer and scheduler for the Big network\n",
    "# # optimizer\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "# \n",
    "# # learning rate scheduler\n",
    "# scheduler = StepLR(optimizer, step_size=4, gamma=0.1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # tqdm to show a progress bar \n",
    "    for i, data in tqdm(enumerate(trainLoader, 0), total=len(trainLoader)):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs, predictJigSaw=False)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    simpleCNNLossOvertime.append(round(running_loss/len(trainLoader), 2))\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    # put the network in evaluation mode\n",
    "    net.eval()\n",
    "\n",
    "    # check accuracy on val set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(valLoader, total=len(valLoader)):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images, predictJigSaw=False)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    accuracy = round(accuracy, 2)\n",
    "    simpleCNNAccuracyOvertime.append(accuracy)\n",
    "    print(f\"Epoch {epoch + 1}, loss: {round(running_loss/len(trainLoader), 2)}, accuracy: {accuracy}, lr: {scheduler.get_last_lr()}\")\n",
    "\n",
    "    # save model after each epoch\n",
    "    torch.save(net.state_dict(), f\"Models/{size}-model_{epoch}.pth\")\n",
    "    \n",
    "    # put the network back in training mode\n",
    "    net.train()\n",
    "\n",
    "print('Finished Training')\n",
    "print(simpleCNNLossOvertime)\n",
    "print(simpleCNNAccuracyOvertime)\n",
    "\n",
    "# plot loss and accuracy in separate graphs\n",
    "plt.plot(simpleCNNLossOvertime)\n",
    "plt.title('Simple CNN loss')\n",
    "plt.grid()\n",
    "plt.savefig('Media/loss.png')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(simpleCNNAccuracyOvertime)\n",
    "plt.title('Simple CNN accuracy')\n",
    "plt.grid()\n",
    "plt.savefig('Media/accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Starting testing\")\n",
    "\n",
    "# put the network in evaluation mode\n",
    "net.eval()\n",
    "\n",
    "# validate the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(testLoader, total=len(testLoader)):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images, predictJigSaw=False)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_true += labels.tolist()\n",
    "        y_pred += predicted.tolist()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "# save the most misclassified classes, using y_true and y_pred\n",
    "misclassified = {}\n",
    "for i in range(251):\n",
    "    misclassified[i] = 0\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i] != y_pred[i]:\n",
    "        misclassified[y_pred[i]] += 1\n",
    "\n",
    "misclassified = {k: v for k, v in sorted(misclassified.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# print the first 10 misclassified classes using \"dictionary\" dictionary\n",
    "print({dictionary[k]: v for k, v in list(misclassified.items())[:10]})\n",
    "\n",
    "print(\"Calculating the confusion matrix\")\n",
    "\n",
    "# confusion matrix\n",
    "num_classes = len(dictionary)\n",
    "confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "for t, p in zip(y_true, y_pred):\n",
    "    confusion_matrix[t, p] += 1\n",
    "\n",
    "confusion_matrix = confusion_matrix.numpy()\n",
    "\n",
    "# get class names\n",
    "class_names = [dictionary[i] for i in range(num_classes)]\n",
    "\n",
    "# plot the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(50, 50))\n",
    "cax = ax.matshow(confusion_matrix, cmap='magma', interpolation='nearest')\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# labels\n",
    "ax.set_xticks(np.arange(num_classes))\n",
    "ax.set_yticks(np.arange(num_classes))\n",
    "ax.set_xticklabels(class_names, rotation=90)\n",
    "ax.set_yticklabels(class_names)\n",
    "\n",
    "# set axis labels\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "\n",
    "# save the figure\n",
    "plt.savefig('Media/confusion_matrix_simpleCNN.png')\n",
    "plt.close()\n",
    "\n",
    "# accuracy calculation\n",
    "accuracy = correct / total\n",
    "print(f\"Testings accuracy: {accuracy}\")\n",
    "\n",
    "# f1 score calculation\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(f\"F1 score: {f1}\")\n",
    "\n",
    "weight = net.conv1.weight.detach().cpu().numpy()\n",
    "\n",
    "# plotting the filters\n",
    "num_filters = weight.shape[0]\n",
    "num_cols = 8\n",
    "num_rows = num_filters // num_cols + 1\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i in range(num_filters):\n",
    "    plt.subplot(num_rows, num_cols, i + 1)\n",
    "    plt.imshow(weight[i, 0])\n",
    "    plt.axis('off')\n",
    "plt.savefig('Media/firstLayer_simpleCNN.png')\n",
    "plt.close()"
   ],
   "id": "165af3a955f18454",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Self Supervised Learning Task",
   "id": "a4125b0c4c752760"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataset class which extends the Dataset class to compose the jigsaw puzzle dataset\n",
    "class JigsawPuzzleDataset(Dataset):\n",
    "    def __init__(self, dataset, grid_size=2):\n",
    "        self.dataset = dataset\n",
    "        self.grid_size = grid_size\n",
    "        self.permutations = self._generate_permutations(grid_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, _ = self.dataset[index]\n",
    "        image_pieces = self._divide_image(image)\n",
    "        shuffled_pieces, shuffled_order = self._shuffle_pieces(image_pieces)\n",
    "\n",
    "        # create a new blank image of the correct size\n",
    "        reconstructed_image = torch.zeros_like(image)\n",
    "\n",
    "        piece_w, piece_h = image.shape[1] // self.grid_size, image.shape[2] // self.grid_size\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                \n",
    "                # calculate the position of the piece in the reconstructed image\n",
    "                pos = (j * piece_w, i * piece_h)\n",
    "                \n",
    "                # paste the piece at the correct position\n",
    "                reconstructed_image[:, pos[1]:pos[1]+piece_h, pos[0]:pos[0]+piece_w] = shuffled_pieces[i * self.grid_size + j]\n",
    "\n",
    "        # one-hot encode the permutation index to a vector\n",
    "        permutation_index = self.permutations.index(tuple(shuffled_order))\n",
    "        label = torch.zeros(len(self.permutations), dtype=torch.float)\n",
    "        label[permutation_index] = 1.0\n",
    "\n",
    "        return reconstructed_image, label\n",
    "\n",
    "    def _divide_image(self, image):\n",
    "        pieces = []\n",
    "\n",
    "        # divide image into pieces\n",
    "        piece_w, piece_h = image.shape[1] // self.grid_size, image.shape[2] // self.grid_size\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                piece = image[:, i*piece_h:(i+1)*piece_h, j*piece_w:(j+1)*piece_w]\n",
    "                pieces.append(piece)\n",
    "\n",
    "        return pieces\n",
    "\n",
    "    def _shuffle_pieces(self, pieces):\n",
    "\n",
    "        # shuffle the pieces\n",
    "        shuffled_order = random.choice(self.permutations)\n",
    "        shuffled_pieces = [pieces[i] for i in shuffled_order]\n",
    "        return shuffled_pieces, shuffled_order\n",
    "\n",
    "    def _generate_permutations(self, grid_size):\n",
    "        \n",
    "        # generate all possible permutations of the grid\n",
    "        indices = list(range(grid_size ** 2))\n",
    "        permutations = list(itertools.permutations(indices))\n",
    "        return permutations"
   ],
   "id": "eef554da3dd8cd39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pipeline\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((size, size), antialias= True),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# load the dataset\n",
    "trainSet = torchvision.datasets.ImageFolder(root= datasetPath + 'processedData/processed_train_set', transform=transforms)\n",
    "testSet = torchvision.datasets.ImageFolder(root= datasetPath + 'processedData/processed_test_set', transform=transforms)\n",
    "valSet = torchvision.datasets.ImageFolder(root= datasetPath + 'processedData/processed_val_set', transform=transforms)\n",
    "\n",
    "jigsaw_dataset = JigsawPuzzleDataset(trainSet)\n",
    "jigsaw_datasetTest = JigsawPuzzleDataset(testSet)\n",
    "jigsaw_datasetVal = JigsawPuzzleDataset(valSet)\n",
    "\n",
    "jigsaw_loader = DataLoader(jigsaw_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "jigsaw_loaderTest = DataLoader(jigsaw_datasetTest, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "jigsaw_loaderVal = DataLoader(jigsaw_datasetVal, batch_size=batch_size, shuffle=True, num_workers=4)"
   ],
   "id": "7937000aa758ce63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# re-initialize the network\n",
    "ssl_model = Net(num_classes=251, size=size)\n",
    "ssl_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer and scheduler for the Small network\n",
    "optimizer = torch.optim.Adam(ssl_model.parameters(), lr=0.001)\n",
    "\n",
    "# learning rate scheduler\n",
    "scheduler = CosineAnnealingLR(optimizer, num_epochs, 0, -1)\n",
    "\n",
    "# optimizer and scheduler for the Big network\n",
    "# optimizer = torch.optim.Adam(ssl_model.parameters(), lr=0.001)\n",
    "# \n",
    "# # learning rate scheduler\n",
    "# scheduler = StepLR(optimizer, step_size=4, gamma=0.1)\n",
    "\n",
    "SSLLossOvertime = []\n",
    "SSLAccuracyOvertime = []\n",
    "\n",
    "ssl_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(jigsaw_loader, total=len(jigsaw_loader)):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ssl_model(images, predictJigSaw=True)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    SSLLossOvertime.append(round(running_loss / len(jigsaw_loader), 2))\n",
    "\n",
    "    # put the model in evaluation mode\n",
    "    ssl_model.eval()\n",
    "\n",
    "    # check accuracy on val set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(jigsaw_loaderVal, total=len(jigsaw_loaderVal)):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = ssl_model(images, predictJigSaw=True)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    accuracy = round(accuracy, 2)\n",
    "    SSLAccuracyOvertime.append(accuracy)\n",
    "    print(f\"Epoch {epoch + 1}, loss: {round(running_loss / len(jigsaw_loader), 2)}, accuracy: {accuracy}\")\n",
    "\n",
    "    # put the model back in training mode\n",
    "    ssl_model.train()\n",
    "\n",
    "    # save the model after each epoch\n",
    "    torch.save(ssl_model.state_dict(), f\"ssl_model_epoch_{epoch + 1}.pth\")\n",
    "    \n",
    "\n",
    "print(\"Finished SSL Training\")\n",
    "print(SSLLossOvertime)\n",
    "print(SSLAccuracyOvertime)\n",
    "\n",
    "# plot loss and accuracy in separate graphs\n",
    "plt.plot(SSLLossOvertime)\n",
    "plt.title('SSL Loss')\n",
    "plt.grid()\n",
    "plt.savefig('Media/SSLLoss.png')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(SSLAccuracyOvertime)\n",
    "plt.title('SSL Accuracy')\n",
    "plt.grid()\n",
    "plt.savefig('Media/SSLAccuracy.png')\n",
    "plt.close()\n",
    "\n",
    "# start testing\n",
    "print(\"Starting testing\")\n",
    "\n",
    "# put the model in evaluation mode\n",
    "ssl_model.eval()\n",
    "\n",
    "# validate the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(jigsaw_loaderTest, total=len(jigsaw_loaderTest)):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = ssl_model(images, predictJigSaw=True)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        labels = torch.argmax(labels, dim=1)\n",
    "        y_true += labels.tolist()\n",
    "        y_pred += predicted.tolist()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Testings accuracy: {accuracy}\")\n",
    "\n",
    "print(\"Most misclassified classes\")\n",
    "misclassified = {}\n",
    "for i in range(24):\n",
    "    misclassified[i] = 0\n",
    "    \n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i] != y_pred[i]:\n",
    "        misclassified[y_pred[i]] += 1\n",
    "\n",
    "misclassified = {k: v for k, v in sorted(misclassified.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# print the first 10 misclassified classes using \"dictionary\" dictionary\n",
    "print({dictionary[k]: v for k, v in list(misclassified.items())[:10]})\n",
    "\n",
    "print(\"Calculating the confusion matrix\")\n",
    "\n",
    "# confusion matrix\n",
    "num_classes = len(dictionary)\n",
    "confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "\n",
    "# populate the confusion matrix\n",
    "for t, p in zip(y_true, y_pred):\n",
    "    confusion_matrix[t, p] += 1\n",
    "\n",
    "# convert the confusion matrix to numpy \n",
    "confusion_matrix = confusion_matrix.numpy()\n",
    "\n",
    "# get class names\n",
    "class_names = [dictionary[i] for i in range(num_classes)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(50, 50))\n",
    "cax = ax.matshow(confusion_matrix, cmap='magma', interpolation='nearest')\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# ticks and labels\n",
    "ax.set_xticks(np.arange(num_classes))\n",
    "ax.set_yticks(np.arange(num_classes))\n",
    "ax.set_xticklabels(class_names, rotation=90)\n",
    "ax.set_yticklabels(class_names)\n",
    "\n",
    "# set axis labels\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "\n",
    "# save the figure\n",
    "plt.savefig('Media/confusion_matrix_simpleCNN.png')\n",
    "plt.close()\n",
    "\n",
    "# f1 score calculation\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(f\"F1 score: {f1}\")\n",
    "\n",
    "weight = ssl_model.conv1.weight.detach().cpu().numpy()\n",
    "\n",
    "# plotting the filters\n",
    "num_filters = weight.shape[0] \n",
    "num_cols = 8\n",
    "num_rows = num_filters // num_cols + 1 \n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i in range(num_filters):\n",
    "    plt.subplot(num_rows, num_cols, i + 1)\n",
    "    plt.imshow(weight[i, 0])\n",
    "    plt.axis('off')\n",
    "plt.savefig('Media/firstLayer_SSL.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"train the CNN with the new weights\")\n",
    "\n",
    "classification_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((size, size)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "classification_dataset = torchvision.datasets.ImageFolder(root=datasetPath + \"processedData/processed_train_set\",\n",
    "                                              transform=classification_transform)\n",
    "classification_datasetTest = torchvision.datasets.ImageFolder(root=datasetPath + \"processedData/processed_test_set\",\n",
    "                                                  transform=classification_transform)\n",
    "classification_datasetVal = torchvision.datasets.ImageFolder(root=datasetPath +  \"processedData/processed_val_set\",\n",
    "                                                 transform=classification_transform)\n",
    "\n",
    "classification_loader = DataLoader(classification_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "classification_loaderTest = DataLoader(classification_datasetTest, batch_size=batch_size, shuffle=True,\n",
    "                                       num_workers=4)\n",
    "classification_loaderVal = DataLoader(classification_datasetVal, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# fine-tune the SSL model for classification\n",
    "ssl_model.fc2 = nn.Linear(ssl_model.fc2.in_features, 251)\n",
    "ssl_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer and scheduler for the Small network\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(ssl_model.parameters(), lr=0.001)\n",
    "\n",
    "# learning rate scheduler\n",
    "scheduler = CosineAnnealingLR(optimizer, num_epochs, 0, -1)\n",
    "\n",
    "# optimizer and scheduler for the Big network\n",
    "# optimizer = torch.optim.Adam(ssl_model.parameters(), lr=0.001)\n",
    "# \n",
    "# # learning rate scheduler\n",
    "# scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "SSLCNNLossOvertime = []\n",
    "SSLCNNAccuracyOvertime = []\n",
    "\n",
    "ssl_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(classification_loader, total=len(classification_loader)):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ssl_model(images, predictJigSaw=False)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    SSLCNNLossOvertime.append(round(running_loss / len(classification_loader), 2))\n",
    "\n",
    "    # put the model in evaluation mode\n",
    "    ssl_model.eval()\n",
    "\n",
    "    # check accuracy on val set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(classification_loaderVal, total=len(classification_loaderVal)):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = ssl_model(images, predictJigSaw=False)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    accuracy = round(accuracy, 2)\n",
    "    SSLCNNAccuracyOvertime.append(accuracy)\n",
    "    print(f\"Epoch {epoch + 1}, loss: {round(running_loss / len(classification_loader), 2)}, accuracy: {accuracy}, lr: {scheduler.get_last_lr()}\")\n",
    "\n",
    "    # put the model back in training mode\n",
    "    ssl_model.train()\n",
    "\n",
    "    # save the model after each epoch\n",
    "    torch.save(ssl_model.state_dict(), f\"ssl_model_classification_epoch_{epoch + 1}.pth\")\n",
    "\n",
    "print(\"Finished Classification Training\")\n",
    "print(SSLCNNLossOvertime)\n",
    "print(SSLCNNAccuracyOvertime)\n",
    "\n",
    "# plot loss and accuracy in separate graphs\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SSLCNNLossOvertime)\n",
    "plt.title('SSL CNN Loss')\n",
    "plt.grid()\n",
    "plt.savefig('Media/classification_loss.png')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(SSLCNNAccuracyOvertime)\n",
    "plt.title('SSL CNN Accuracy')\n",
    "plt.grid()\n",
    "plt.savefig('Media/classification_accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "# start testing\n",
    "print(\"Starting testing\")\n",
    "\n",
    "# put the model in evaluation mode\n",
    "ssl_model.eval()\n",
    "\n",
    "# validate the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(classification_loaderTest, total=len(classification_loaderTest)):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = ssl_model(images, predictJigSaw=False)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        y_true += labels.tolist()\n",
    "        y_pred += predicted.tolist()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Testings accuracy: {accuracy}\")\n",
    "\n",
    "print(\"Most misclassified classes\")\n",
    "misclassified = {}\n",
    "for i in range(251):\n",
    "    misclassified[i] = 0\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i] != y_pred[i]:\n",
    "        misclassified[y_pred[i]] += 1\n",
    "        \n",
    "misclassified = {k: v for k, v in sorted(misclassified.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# printing the first 10 misclassified classes using \"dictionary\" dictionary\n",
    "print({dictionary[k]: v for k, v in list(misclassified.items())[:10]})\n",
    "\n",
    "print(\"Calculating the confusion matrix\")\n",
    "\n",
    "# confusion matrix\n",
    "num_classes = len(dictionary)\n",
    "confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "\n",
    "for t, p in zip(y_true, y_pred):\n",
    "    confusion_matrix[t, p] += 1\n",
    "\n",
    "confusion_matrix = confusion_matrix.numpy()\n",
    "\n",
    "# get class names\n",
    "class_names = [dictionary[i] for i in range(num_classes)]\n",
    "\n",
    "# plot the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(50, 50))\n",
    "cax = ax.matshow(confusion_matrix, cmap='magma', interpolation='nearest')\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# ticks and labels\n",
    "ax.set_xticks(np.arange(num_classes))\n",
    "ax.set_yticks(np.arange(num_classes))\n",
    "ax.set_xticklabels(class_names, rotation=90)\n",
    "ax.set_yticklabels(class_names)\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "\n",
    "# save the figure\n",
    "plt.savefig('Media/confusion_matrix_CNNSSL.png')\n",
    "plt.close()\n",
    "\n",
    "# f1 score\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(f\"F1 score: {f1}\")\n",
    "\n",
    "weight = ssl_model.conv1.weight.detach().cpu().numpy()\n",
    "\n",
    "num_filters = weight.shape[0]\n",
    "num_cols = 8\n",
    "num_rows = num_filters // num_cols + 1\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i in range(num_filters):\n",
    "    plt.subplot(num_rows, num_cols, i + 1)\n",
    "    plt.imshow(weight[i, 0])\n",
    "    plt.axis('off')\n",
    "plt.savefig('Media/firstLayer_SSL_CNN.png')\n",
    "plt.close()"
   ],
   "id": "a5044ecd86edf89e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting compared loss and accuracies of the models\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SSLCNNLossOvertime)\n",
    "plt.plot(simpleCNNLossOvertime)\n",
    "plt.title('CNN Loss Compared')\n",
    "plt.legend(['SSL CNN', 'CNN'])\n",
    "plt.grid()\n",
    "plt.savefig('./Media/lossCompared.png')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SSLCNNAccuracyOvertime)\n",
    "plt.plot(simpleCNNAccuracyOvertime)\n",
    "plt.title('CNN Accuracy Compared')\n",
    "plt.legend(['SSL CNN', 'CNN'])\n",
    "plt.grid()\n",
    "plt.savefig('./Media/accuracyCompared.png')\n",
    "plt.close()"
   ],
   "id": "6c58f7c19f24b602",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ea746544401c0062"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
