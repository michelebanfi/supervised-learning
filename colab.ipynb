{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Donwload data",
   "id": "7d414ecde9e8cb14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://food-x.s3.amazonaws.com/annot.tar\n",
    "!wget https://food-x.s3.amazonaws.com/train.tar\n",
    "!wget https://food-x.s3.amazonaws.com/val.tar\n",
    "\n",
    "!tar -xvf annot.tar -C /Data\n",
    "!tar -xvf train.tar -C /Data\n",
    "!tar -xvf val.tar -C /Data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocessing",
   "id": "863f4d774e840c05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n",
    "print(\"running on:\", device)\n",
    "\n",
    "\n",
    "# class list pre processing\n",
    "def add_string(file, string):\n",
    "    with open(file, 'r') as original: data = original.read()\n",
    "    if data.startswith(string): return\n",
    "    with open(file, 'w') as modified: modified.write(string + data)\n",
    "\n",
    "\n",
    "add_string('Data/annot/train_info.csv', 'class,image\\n')\n",
    "add_string('Data/annot/val_info.csv', 'class,image\\n')\n",
    "\n",
    "# Directory:\n",
    "trainDirectory = 'Data/train_set'\n",
    "testDirectory = 'Data/val_set'\n",
    "\n",
    "processedTrainDirectory = 'Data/processedData/processed_train_set'\n",
    "processedTestDirectory = 'Data/processedData/processed_test_set'\n",
    "processedValDirectory = 'Data/processedData/processed_val_set'\n",
    "\n",
    "# Creation of the directory if they dont exist\n",
    "os.makedirs(processedTrainDirectory, exist_ok=True)\n",
    "os.makedirs(processedTestDirectory, exist_ok=True)\n",
    "os.makedirs(processedValDirectory, exist_ok=True)\n",
    "\n",
    "# load images classes from \"train_info.csv\"\n",
    "trainInfo = pd.read_csv('Data/annot/train_info.csv')\n",
    "testInfo = pd.read_csv('Data/annot/val_info.csv')\n",
    "\n",
    "trainClasses = trainInfo['class'].unique()\n",
    "testClasses = testInfo['class'].unique()\n",
    "\n",
    "# create folders for each train class\n",
    "for trainClass in trainClasses:\n",
    "    os.makedirs(os.path.join(processedTrainDirectory, str(trainClass)), exist_ok=True)\n",
    "\n",
    "# create folders for each test class\n",
    "for testClass in testClasses:\n",
    "    os.makedirs(os.path.join(processedTestDirectory, str(testClass)), exist_ok=True)\n",
    "\n",
    "# create folders for each validation class (using the train classes)\n",
    "for valClass in trainClasses:\n",
    "    os.makedirs(os.path.join(processedValDirectory, str(valClass)), exist_ok=True)\n",
    "\n",
    "\n",
    "def process_images(input_dir, output_dir, set_type):\n",
    "    image_path_pattern = os.path.join(input_dir, \"*.jpg\")\n",
    "    image_paths = glob.glob(image_path_pattern)\n",
    "\n",
    "    pbar = tqdm(total=len(image_paths), desc='Processing', unit='frame')\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # get image class\n",
    "        if set_type == \"train\":\n",
    "            imageClass = trainInfo[trainInfo['image'] == os.path.basename(image_path)]['class'].values[0]\n",
    "        else:\n",
    "            imageClass = testInfo[testInfo['image'] == os.path.basename(image_path)]['class'].values[0]\n",
    "\n",
    "        # Check if the image is in RBG format\n",
    "        if (len(image.shape) != 3):\n",
    "            print(\"is not RGB\")\n",
    "\n",
    "        # Resize of the images to a common size\n",
    "        image = cv2.resize(image, (256, 256))\n",
    "\n",
    "        # path to save the images\n",
    "        base_filename = os.path.basename(image_path)\n",
    "        processed_image_path = os.path.join(output_dir, str(imageClass), base_filename)\n",
    "\n",
    "        # saving the images\n",
    "        cv2.imwrite(processed_image_path, image)\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "\n",
    "def valSet():\n",
    "    # take 3% of the train set and create a vaidation set\n",
    "    image_path_pattern = os.path.join(processedTrainDirectory, \"*.jpg\")\n",
    "    image_paths = glob.glob(image_path_pattern)\n",
    "\n",
    "    # 3% of the train set drawn randomly\n",
    "    val_set = np.random.choice(image_paths, int(len(image_paths) * 0.03), replace=False)\n",
    "\n",
    "    # path to save the images\n",
    "    for image_path in val_set:\n",
    "        # get image class from train set\n",
    "        imageClass = trainInfo[trainInfo['image'] == os.path.basename(image_path)]['class'].values[0]\n",
    "\n",
    "        base_filename = os.path.basename(image_path)\n",
    "        processed_image_path = os.path.join(processedValDirectory, str(imageClass), base_filename)\n",
    "\n",
    "        # move the images to the test set\n",
    "        os.rename(image_path, processed_image_path)\n",
    "\n",
    "\n",
    "print(\"Processing train set\")\n",
    "process_images(trainDirectory, processedTrainDirectory, \"train\")\n",
    "\n",
    "print(\"Processing test set\")\n",
    "process_images(testDirectory, processedTestDirectory, \"test\")\n",
    "\n",
    "# Creation of the validation set\n",
    "print(\"Creating validation set\")\n",
    "valSet()\n"
   ],
   "id": "407e1a037280cff0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Network",
   "id": "caf10d59c14b8439"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        # Define the feature extraction part of the network\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Define the classification part of the network\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, 256)  # Adjusted size due to pooling\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature extraction\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # Flatten the tensor for the fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Classification\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def trainStep(self, x, y):\n",
    "        self.optimizer.zero_grad()\n",
    "        out = self.forward(x)\n",
    "        loss = self.criterion(out, y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss"
   ],
   "id": "9277e69400858dd8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "f06a33f9099feed3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torchvision.datasets\n",
    "from net import Net\n",
    "from torchsummary import summary\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def main():\n",
    "    train_on_gpu = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n",
    "    print(\"running on: \", device)\n",
    "\n",
    "    net = Net(num_classes=251)\n",
    "    summary(net, (3, 64, 64))\n",
    "    net.to(device)\n",
    "\n",
    "    lossOvertime = []\n",
    "    accuracyOvertime = []\n",
    "\n",
    "    # Define data transformations pipeline\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Resize((64, 64))\n",
    "    ])\n",
    "\n",
    "    trainSet = torchvision.datasets.ImageFolder(root='./Data/processedData/processed_train_set', transform=transforms)\n",
    "    testSet = torchvision.datasets.ImageFolder(root='./Data/processedData/processed_test_set', transform=transforms)\n",
    "\n",
    "    trainLoader = DataLoader(trainSet, batch_size=64, shuffle=True, num_workers=2)\n",
    "    testLoader = DataLoader(testSet, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "    epochs = 5\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in tqdm(enumerate(trainLoader, 0), total=len(trainLoader)):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            loss = net.trainStep(inputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        lossOvertime.append(running_loss)\n",
    "\n",
    "\n",
    "        # check accuracy on test set\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testLoader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        accuracyOvertime.append(accuracy)\n",
    "        print(f\"Epoch {epoch + 1}, loss: {running_loss}, accuracy: {accuracy}\")\n",
    "\n",
    "        # save model\n",
    "        torch.save(net.state_dict(), f\"model_{epoch}.pth\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "id": "fd760cdaada87246"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
