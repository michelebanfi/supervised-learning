{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!mkdir Data\n",
    "!mkdir Models\n",
    "!mkdir Media\n",
    "!mkdir Media/SSL\n",
    "!mkdir Models/SSL"
   ],
   "id": "3e8944c8978d44e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-11T08:59:10.133276Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "mean = [0.6388, 0.5446, 0.4452]\n",
    "std = [0.2252, 0.2437, 0.2661]\n",
    "\n",
    "class JigsawPuzzleDataset(Dataset):\n",
    "    def __init__(self, dataset, grid_size=2):\n",
    "        self.dataset = dataset\n",
    "        self.grid_size = grid_size\n",
    "        self.permutations = self._generate_permutations(grid_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, _ = self.dataset[index]\n",
    "        image_pieces, correct_order = self._divide_image(image)\n",
    "        shuffled_pieces, shuffled_order = self._shuffle_pieces(image_pieces, correct_order)\n",
    "\n",
    "        # Create a new blank image of the correct size\n",
    "        reconstructed_image = torch.zeros_like(image)\n",
    "\n",
    "        piece_w, piece_h = image.shape[1] // self.grid_size, image.shape[2] // self.grid_size\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                # Calculate the position of the piece in the reconstructed image\n",
    "                pos = (j * piece_w, i * piece_h)\n",
    "                # Paste the piece at the correct position\n",
    "                reconstructed_image[:, pos[1]:pos[1]+piece_h, pos[0]:pos[0]+piece_w] = shuffled_pieces[i * self.grid_size + j]\n",
    "\n",
    "        # One-hot encode the permutation index\n",
    "        permutation_index = self.permutations.index(tuple(shuffled_order))\n",
    "        label = torch.zeros(len(self.permutations), dtype=torch.float)\n",
    "        label[permutation_index] = 1.0\n",
    "\n",
    "        return reconstructed_image, label\n",
    "\n",
    "    def _divide_image(self, image):\n",
    "        pieces = []\n",
    "\n",
    "        piece_w, piece_h = image.shape[1] // self.grid_size, image.shape[2] // self.grid_size\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                piece = image[:, i*piece_h:(i+1)*piece_h, j*piece_w:(j+1)*piece_w]\n",
    "                pieces.append(piece)\n",
    "\n",
    "        correct_order = list(range(self.grid_size ** 2))\n",
    "        return pieces, correct_order\n",
    "\n",
    "    def _shuffle_pieces(self, pieces, correct_order):\n",
    "        shuffled_order = random.choice(self.permutations)\n",
    "        shuffled_pieces = [pieces[i] for i in shuffled_order]\n",
    "        return shuffled_pieces, shuffled_order\n",
    "\n",
    "    def _generate_permutations(self, grid_size):\n",
    "        indices = list(range(grid_size ** 2))\n",
    "        permutations = list(itertools.permutations(indices))\n",
    "        return permutations\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes, size):\n",
    "\n",
    "        # list of the conv layers parameters\n",
    "        convLayerNumber = 7\n",
    "        kernels = [11, 7, 7, 5, 5, 3, 3]\n",
    "        paddings = [1, 1, 1, 1, 1, 1, 1]\n",
    "        poolingsStride = [2, 0, 2, 0, 2, 0, 2]\n",
    "        poolingsKernels = [2, 0, 2, 0, 2, 0, 2]\n",
    "        filters = [8, 16, 16, 32, 64, 64, 128]\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        # Define the feature extraction part of the network\n",
    "        self.conv1 = nn.Conv2d(3, filters[0], kernel_size=kernels[0], padding=paddings[0])\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=poolingsKernels[0], stride=poolingsStride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv2d(filters[0], filters[1], kernel_size=kernels[1], padding=paddings[1])\n",
    "        self.conv3 = nn.Conv2d(filters[1], filters[2], kernel_size=kernels[2], padding=paddings[2])\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=poolingsKernels[2], stride=poolingsStride[2])\n",
    "\n",
    "        self.conv4 = nn.Conv2d(filters[2], filters[3], kernel_size=kernels[3], padding=paddings[3])\n",
    "        self.conv5 = nn.Conv2d(filters[3], filters[4], kernel_size=kernels[4], padding=paddings[4])\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=poolingsKernels[4], stride=poolingsStride[4])\n",
    "\n",
    "        self.conv6 = nn.Conv2d(filters[4], filters[5], kernel_size=kernels[5], padding=paddings[5])\n",
    "        self.conv7 = nn.Conv2d(filters[5], filters[6], kernel_size=kernels[6], padding=paddings[6])\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=poolingsKernels[6], stride=poolingsStride[6])\n",
    "\n",
    "        # now we want to calculate the final dimension of all the conv layers\n",
    "        for i in range(convLayerNumber):\n",
    "            size = (size - kernels[i] + 2 * paddings[i]) / 1 + 1\n",
    "            if (poolingsKernels[i] != 0):\n",
    "                size = int((size - poolingsKernels[i]) / poolingsStride[i] + 1)\n",
    "\n",
    "        fc1_input_size = filters[6] * size * size\n",
    "\n",
    "        print(\"First layer size: \", fc1_input_size)\n",
    "\n",
    "        # Define the classification part of the network\n",
    "        self.fc1 = nn.Linear(fc1_input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "\n",
    "class NetWithJigSawPrediction(Net):\n",
    "    def __init__(self, num_classes, size):\n",
    "        super(NetWithJigSawPrediction, self).__init__(num_classes, size)\n",
    "        self.rotation_fc = nn.Linear(self.fc1.in_features, 2)\n",
    "\n",
    "    def forward(self, x, predict_rotation=False):\n",
    "        # Feature extraction\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = F.leaky_relu(self.conv3(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv4(x))\n",
    "        x = F.leaky_relu(self.conv5(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv6(x))\n",
    "        x = F.leaky_relu(self.conv7(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # Flatten the tensor for the fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        if predict_rotation:\n",
    "            return self.rotation_fc(x)\n",
    "        else:\n",
    "            x = F.leaky_relu(self.fc1(x))\n",
    "            x = self.dropout(x)\n",
    "            return self.fc2(x)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to a standard size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "trainSet = datasets.ImageFolder(root='/kaggle/input/supervised/processedData/processed_train_set', transform=transform)\n",
    "testSet = datasets.ImageFolder(root='/kaggle/input/supervised/processedData/processed_test_set', transform=transform)\n",
    "valSet = datasets.ImageFolder(root='/kaggle/input/supervised/processedData/processed_val_set', transform=transform)\n",
    "rotation_dataset = JigsawPuzzleDataset(trainSet)\n",
    "rotation_datasetTest = JigsawPuzzleDataset(testSet)\n",
    "rotation_datasetVal = JigsawPuzzleDataset(valSet)\n",
    "\n",
    "batch_size = 64\n",
    "rotation_loader = DataLoader(rotation_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "rotation_loaderTest = DataLoader(rotation_datasetTest, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "rotation_loaderVal = DataLoader(rotation_datasetVal, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "print(\"Validation:\", len(rotation_loader.dataset))\n",
    "print(\"Training:\", len(rotation_loaderTest.dataset))\n",
    "print(\"Test:\", len(rotation_loaderVal.dataset))\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Running on {device}\")\n",
    "\n",
    "# Initialize the SSL model\n",
    "ssl_model = NetWithJigSawPrediction(num_classes=251, size=128)\n",
    "ssl_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(ssl_model.parameters(), lr=0.001)\n",
    "\n",
    "# define a learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "lossOvertime = []\n",
    "accuracyOvertime = []\n",
    "\n",
    "ssl_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(rotation_loader, total=len(rotation_loader)):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ssl_model(images, predict_rotation=True)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    lossOvertime.append(round(running_loss / len(rotation_loader), 2))\n",
    "\n",
    "    # put the model in evaluation mode\n",
    "    ssl_model.eval()\n",
    "\n",
    "    # check accuracy on val set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(rotation_loaderVal, total=len(rotation_loaderVal)):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = ssl_model(images, predict_rotation=True)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    accuracy = round(accuracy, 2)\n",
    "    accuracyOvertime.append(accuracy)\n",
    "    print(f\"Epoch {epoch + 1}, loss: {round(running_loss / len(rotation_loader), 2)}, accuracy: {accuracy}\")\n",
    "\n",
    "    # put the model back in training mode\n",
    "    ssl_model.train()\n",
    "\n",
    "    # save the model after each epoch\n",
    "    torch.save(ssl_model.state_dict(), f\"ssl_model_epoch_{epoch + 1}.pth\")\n",
    "\n",
    "print(\"Finished SSL Training\")\n",
    "print(lossOvertime)\n",
    "print(accuracyOvertime)\n",
    "\n",
    "# plot loss and accuracy in separate graphs\n",
    "plt.plot(lossOvertime)\n",
    "plt.savefig('Media/SSL/loss.png')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(accuracyOvertime)\n",
    "plt.savefig('Media/SSL/accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "# start testing\n",
    "print(\"Starting testing\")\n",
    "\n",
    "# put the model in evaluation mode\n",
    "ssl_model.eval()\n",
    "\n",
    "# validate the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in rotation_loaderTest:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = ssl_model(images, predict_rotation=True)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Testings accuracy: {accuracy}\")\n",
    "\n",
    "# load the best model\n",
    "ssl_model.load_state_dict(torch.load(\"ssl_model_epoch_5.pth\"))\n",
    "\n",
    "classification_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "classification_dataset = datasets.ImageFolder(root=\"/kaggle/input/supervised/processedData/processed_train_set\",\n",
    "                                          transform=classification_transform)\n",
    "classification_datasetTest = datasets.ImageFolder(root=\"./kaggle/input/supervised/processedData/processed_test_set\",\n",
    "                                              transform=classification_transform)\n",
    "classification_datasetVal = datasets.ImageFolder(root=\"/kaggle/input/supervised/processedData/processed_val_set\",\n",
    "                                             transform=classification_transform)\n",
    "\n",
    "classification_loader = DataLoader(classification_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "classification_loaderTest = DataLoader(classification_datasetTest, batch_size=batch_size, shuffle=True,\n",
    "                                   num_workers=4)\n",
    "classification_loaderVal = DataLoader(classification_datasetVal, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Fine-tune the SSL model for classification\n",
    "ssl_model.fc2 = nn.Linear(ssl_model.fc2.in_features, 251)  # Update the final layer for 251 classes\n",
    "ssl_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(ssl_model.parameters(), lr=0.001)\n",
    "\n",
    "# define a learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "lossOvertime = []\n",
    "accuracyOvertime = []\n",
    "\n",
    "ssl_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(classification_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ssl_model(images, predict_rotation=False)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    lossOvertime.append(round(running_loss / len(classification_loader), 2))\n",
    "\n",
    "    # put the model in evaluation mode\n",
    "    ssl_model.eval()\n",
    "\n",
    "    # check accuracy on val set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(classification_loaderVal, total=len(classification_loaderVal)):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = ssl_model(images, predict_rotation=False)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    accuracy = round(accuracy, 2)\n",
    "    accuracyOvertime.append(accuracy)\n",
    "    print(f\"Epoch {epoch + 1}, loss: {round(running_loss / len(classification_loader), 2)}, accuracy: {accuracy}\")\n",
    "\n",
    "    # put the model back in training mode\n",
    "    ssl_model.train()\n",
    "\n",
    "    # save the model after each epoch\n",
    "    torch.save(ssl_model.state_dict(), f\"ssl_model_classification_epoch_{epoch + 1}.pth\")\n",
    "\n",
    "print(\"Finished Classification Training\")\n",
    "print(lossOvertime)\n",
    "print(accuracyOvertime)\n",
    "\n",
    "# plot loss and accuracy in separate graphs\n",
    "plt.plot(lossOvertime)\n",
    "plt.savefig('Media/SSL/classification_loss.png')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(accuracyOvertime)\n",
    "plt.savefig('Media/SSL/classification_accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "# start testing\n",
    "print(\"Starting testing\")\n",
    "\n",
    "# put the model in evaluation mode\n",
    "ssl_model.eval()\n",
    "\n",
    "# validate the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in classification_loaderTest:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = ssl_model(images, predict_rotation=False)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Testings accuracy: {accuracy}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 88977\n",
      "Training: 47976\n",
      "Test: 29600\n",
      "Running on cpu\n",
      "First layer size:  3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1391 [00:00<?, ?it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "123b01bf247cffc6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
